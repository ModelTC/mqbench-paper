NNIE
====
NNIE is a Neural Network Inference Engine of Hisilicon. It support INT8/INT16 quantization.

.. _NNIE Quantization Scheme:

Quantization Scheme
---------------------
8/16 bit per-layer logarithmic quantization.

The specific quantization formulation is:

.. math::

    \begin{equation}
        z = \lfloor 16 * \log_2(c) \rceil - 127 \\
        \mathtt{fakequant(x)} = \begin{cases}
            - 2 ^ {\frac{\mathtt{clamp}(\lfloor 16 * \log_2(-x) \rceil - z, 1, 127) + z}{16}}, & x \lt - 2 ^ {\frac{z + 1}{16} - 1} \\
            0, & - 2 ^ {\frac{z + 1}{16} - 1} \le x \lt 2 ^ {\frac{z}{16} - 1} \\
            2 ^ {\frac{\mathtt{clamp}(\lfloor 16 * \log_2(x) \rceil - z, 0, 127) + z}{16}}, & x \ge 2 ^ {\frac{z}{16} - 1} \\
        \end{cases}.
    \end{equation}

where :math:`c` is clipping range. :math:`2 ^ {\frac{z}{16}}` is the smallest positive value that can be represented after quantization.

It represents the integer number in *True Form* format.
The highest bit represents the sign and the reset represents the absolute value of the number.

.. list-table::
   :header-rows: 1
   :align: center

   * - Floating Numer
     - Integer Number
     - Hexadecimal
     - Dequantized Floating Number
   * - :math:`(- \infty, - 2 ^ {\frac{z + 126.5}{16}}]`
     - -127
     - 0xFF
     - :math:`- 2 ^ {\frac{z+127}{16}}`
   * - ...
     - ...
     - ...
     - ...
   * - :math:`(- 2 ^ {\frac{z + 2.5}{16}}, - 2 ^ {\frac{z + 1.5}{16}}]`
     - -2
     - 0x82
     - :math:`- 2 ^ {\frac{z+2}{16}}`
   * - :math:`(- 2 ^ {\frac{z + 1.5}{16}}, - 2 ^ {\frac{z + 1}{16} - 1})`
     - -1
     - 0x81
     - :math:`- 2 ^ {\frac{z+1}{16}}`
   * - :math:`[- 2 ^ {\frac{z + 1}{16} - 1}, 2 ^ {\frac{z}{16} - 1})`
     - -0
     - 0x80
     - 0
   * - :math:`[2 ^ {\frac{z}{16} - 1}, 2 ^ {\frac{z + 0.5}{16}})`
     - 0
     - 0x00
     - :math:`2 ^ {\frac{z}{16}}`
   * - :math:`[2 ^ {\frac{z + 0.5}{16}}, 2 ^ {\frac{z + 1.5}{16}})`
     - 1
     - 0x01
     - :math:`2 ^ {\frac{z+1}{16}}`
   * - ...
     - ...
     - ...
     - ...
   * - :math:`[2 ^ {\frac{z + 126.5}{16}}, + \infty)`
     - 127
     - 0x7F
     - :math:`2 ^ {\frac{z+127}{16}}`

NNIE performs a per-layer quantization, which means the inputs of the same layer share the same :math:`z_a` and the weights of the same layer share the same :math:`z_w`.

In fact, when building engine using the official tool of NNIE, it requires the clipping value :math:`c` rather than :math:`z`. :math:`c` needs to be a number in the :download:`gfpq_param_table_8bit.txt` which ensures that :math:`16 * \log_2{c}` is an integer.

.. attention::
    Pooling: ceil_mode = True

    Avoid using depthwise convolution.

    Only support 2x nearest neighbor upsample.

    For Detection task, you'd better choose RetinaNet structure.

.. _Nart Documentation: http://compile-link.pages.gitlab.bj.sensetime.com/nart/tutorial/switch/nnie.html

`Nart Documentation`_ provides a guide about how to build a quantized NNIE engine using the official tool of Hisilicon.
